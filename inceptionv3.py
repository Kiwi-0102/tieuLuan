# -*- coding: utf-8 -*-
"""InceptionV3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F7yifoowS3ipl1LUHegJperi4m_JjYeH

# **1. Kết nối với Drive**
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/gdrive')
# %cd '/content/gdrive/MyDrive/tieuLuan/dataset/Rice_Leaf_AUG'

pip install tensorflow

"""# **2. Import thư viện**"""

import os
import cv2
import numpy as np
import glob
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Sklearn
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, label_binarize
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_curve, auc, precision_score, recall_score, f1_score

# Keras and TensorFlow
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.applications.inception_v3 import preprocess_input
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.regularizers import l2

"""# **3. Đọc dữ liệu và gán nhãn**"""

# class list
classes = ["Sheath_Blight", "Leaf_Blast", "Leaf_Scald",
           "Brown_Spot", "Bacterial_Leaf_Blight", "Healthy_Rice_Leaf"]

labels = []
image_links = []
class_path ='/content/gdrive/MyDrive/tieuLuan/dataset/Rice_Leaf_AUG'
# load and label emages
for class_name in classes:
    images = glob.glob(f'{class_path}/{class_name}/*.jpg')
    labels.extend([class_name] * len(images))
    image_links.extend(images)
# transfer data to dataframe
data = pd.DataFrame({'labels': labels, 'image_links': image_links})

# check the number of images per layer
data['labels'].value_counts().plot.bar()
plt.show()
print(data['labels'].value_counts())

"""# **4. Chia tập dữ liệu**"""

# split the test set (15%)
images_train_val, images_test, y_train_val, y_test = train_test_split(
    image_links, labels, stratify=labels, test_size=0.15, random_state=42)

print(f'Train + Val: {len(images_train_val)}, Test: {len(images_test)}')

 # split train and validation from the train_val set
images_train, images_val, y_train, y_val = train_test_split(
    images_train_val, y_train_val, stratify=y_train_val, test_size=0.176, random_state=42) # 0.176 * 85% = 15%

print(f'Train: {len(images_train)}, Val: {len(images_val)}, Test: {len(images_test)}')

"""# **5. Chuẩn hóa hình ảnh**"""

# load and resize emages function
def load_and_resize_image(img_path, target_size=(229, 229)):
    img = cv2.imread(img_path)
    if img is None:
        print(f"Error reading image: {img_path}")
        return None
    img_resized = cv2.resize(img, target_size)  # Resize emages
    img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)  # Đổi sang RGB (OpenCV đọc theo BGR)
    img_normalized = img_rgb / 255.0
    return img_normalized
# check emages size
for img_path in image_links:
    img = load_and_resize_image(img_path)
    if img is not None:
        # print proccessed emages
        print(f"Processed image shape for {img_path}: {img.shape}")

# initialize ImageDataGenerator for
# train set with data augmentation
train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest'
)

# validation set (no augmentation)
val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)

# test set (no augmentation)
test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)

# create label encoder
encoder = LabelEncoder()

# transfer label to
# numeric for train and validation dataset
y_train_encoded = encoder.fit_transform(y_train)
y_val_encoded = encoder.transform(y_val)

# one-hot for train and validation dataset
y_train_onehot = to_categorical(y_train_encoded, num_classes=6)
y_val_onehot = to_categorical(y_val_encoded, num_classes=6)

# numeric for test set
y_test_encoded = encoder.transform(y_test)

# Create generators
# for train set
train_generator = train_datagen.flow_from_dataframe(
    dataframe=pd.DataFrame({'image_links': images_train, 'labels': y_train}),
    x_col='image_links',
    y_col='labels',
    target_size=(229, 229),
    batch_size=32,
    class_mode='categorical')

# for validation set
val_generator = val_datagen.flow_from_dataframe(
    dataframe=pd.DataFrame({'image_links': images_val, 'labels': y_val}),
    x_col='image_links',
    y_col='labels',
    target_size=(229, 229),
    batch_size=32,
    class_mode='categorical')

# for test set
test_generator = test_datagen.flow_from_dataframe(
    dataframe=pd.DataFrame({'image_links': images_test, 'labels': y_test}),
    x_col='image_links',
    y_col='labels',
    target_size=(229, 229),
    batch_size=32,
    class_mode='categorical',
    # the order for evaluation
    shuffle=False
)

# check images size in train set
for i in range(6):
    img = load_and_resize_image(images_train[i])
    if img is not None:
        print(f"Image {i} shape: {img.shape}")
batch_images, batch_labels = next(train_generator)
print(f'Batch image shape: {batch_images.shape}')
print(f'Batch label shape: {batch_labels.shape}')

"""# **6. Trích xuất đặc trưng bằng InceptionV3**"""

# create base model with InceptionV3
base_network = InceptionV3(input_shape=(229, 229, 3), include_top=False, weights='imagenet')

# Set the initial layers of InceptionV3 to be untrainable
for layer in base_network.layers:
  # Freeze classes
    layer.trainable = False

# build model
model = Sequential([
    base_network,
    GlobalAveragePooling2D(),
    BatchNormalization(),
    Dropout(0.5),
    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),
    BatchNormalization(),
    Dropout(0.5),
    Dense(6, activation='softmax')
])

# Compile model with optimizer
model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='categorical_crossentropy',
    metrics=['accuracy'])
# build model and show information
model.build((None, 229, 229, 3))
model.summary()

"""# **7. Huấn luyện mô hình**"""

# prevent overfitting
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
# adjust learning speed
lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1)

# train
model.fit(
    train_generator,
    epochs=5,
    validation_data=val_generator,
    callbacks=[early_stopping, lr_scheduler]
)

# Unlock the last 50 layers
for layer in base_network.layers[-50:]:
    layer.trainable = True

# Recompile the model with a smaller Learning Rate
model.compile(
    optimizer=Adam(learning_rate=0.0001),  # ussing smaller learning rate
    loss='categorical_crossentropy',
    metrics=['accuracy'])

# Define callbacks
early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1)

# fine-tune training
history_fine_tune = model.fit(
    train_generator,
    epochs=24,
    validation_data=val_generator,
    callbacks=[early_stopping, lr_scheduler]
)

# Save in native Keras format
model.save('InceptionV3.keras')

"""# **8. Vẽ biểu đồ theo dõi hiệu suất mô hình**"""

# # Plot accuracy graph
plt.figure(figsize=(12, 4))

# Accuracy graph
plt.subplot(1, 2, 1)
plt.plot(history_fine_tune.history['accuracy'], label='Độ chính xác (Train)')
plt.plot(history_fine_tune.history['val_accuracy'], label='Độ chính xác (Validation)')
plt.title('Độ chính xác qua các epochs')
plt.xlabel('Epochs')
plt.ylabel('Độ chính xác')
plt.legend()

# Loss graph
plt.subplot(1, 2, 2)
plt.plot(history_fine_tune.history['loss'], label='Mất mát (Train)')
plt.plot(history_fine_tune.history['val_loss'], label='Mất mát (Validation)')
plt.title('Mất mát qua các epochs')
plt.xlabel('Epochs')
plt.ylabel('Mất mát')
plt.legend()

plt.tight_layout()
plt.savefig('/content/gdrive/MyDrive/tieuLuan/dataset/Rice_Leaf_AUG/performance_tracking_chart_InceptionV3.png')
plt.show()

"""# **9. Đánh giá và lưu mô hình**"""

# evaluate model base on test set
test_loss, test_accuracy = model.evaluate(test_generator)
print(f"Test Accuracy: {test_accuracy:.4f}")

# predict in test set
# Ensure correct order of data
test_generator.reset()
y_pred = model.predict(test_generator)
# Select the class with the highest probability
y_pred_classes = np.argmax(y_pred, axis=1)

# Get the actual labels from the test set
y_true = test_generator.classes

# Calculate the indexes
accuracy = accuracy_score(y_true, y_pred_classes)
precision = precision_score(y_true, y_pred_classes, average='weighted')
recall = recall_score(y_true, y_pred_classes, average='weighted')
f1 = f1_score(y_true, y_pred_classes, average='weighted')

# print results
print(f"Accuracy: {round(accuracy,4)}")
print(f"Precision: {round(precision,4)}")
print(f"Recall: {round(recall,4)}")
print(f"F1-Score: {round(f1,4)}")

# print Confusion Matrix
conf_matrix = confusion_matrix(y_true, y_pred_classes)
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=test_generator.class_indices.keys(), yticklabels=test_generator.class_indices.keys())
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")

# save Confusion Matrix emage
plt.savefig("confusion_matrix_InceptionV3.png", dpi=300, bbox_inches='tight')
plt.show()

# print Classification Report
print("\nClassification Report:")
print(classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys()))

# transfer y_true to binary format
n_classes = len(test_generator.class_indices)
y_true_binary = label_binarize(y_true, classes=range(n_classes))

# draw ROC
plt.figure(figsize=(12, 8))
for i in range(n_classes):
    fpr, tpr, _ = roc_curve(y_true_binary[:, i], y_pred[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f"Class {list(test_generator.class_indices.keys())[i]} (AUC = {roc_auc:.2f})")

# Draw diagonal lines
plt.plot([0, 1], [0, 1], color="gray", linestyle="--")

# Chart Format
plt.title("ROC Curve")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend(loc="lower right")

# save chart to image file
plt.savefig("roc_auc_curve_InceptionV3.png", dpi=300, bbox_inches='tight')
plt.show()